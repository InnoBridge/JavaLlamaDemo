spring.application.name=Application

# Model settings
llama.model.filepath=/home/yi/.hugging_face/models/qwen2.5-coder-14b-instruct-q8_0.gguf
llama.model.n-gpu-layers=62
llama.model.no-kv-offload=false

# Environment variables for CUDA
CUDA_LAUNCH_BLOCKING=0
CUDA_VISIBLE_DEVICES=0
GGML_CUDA_FORCE_CUBLAS=0
GGML_CUDA_FORCE_DMMV=1
GGML_CUDA_FORCE_MMQ=1
GGML_CUDA_FORCE_KQ=1
GGML_CUDA_FORCE_KQV=1
GGML_CUDA_MALLOC_ASYNC=1
GGML_CUDA_NO_PINNED=0

# CUDA settings
io.github.innobridge.llama.lib.path=/home/yi/Documents/JavaLlama/JavaLlama/src/main/resources_linux_cuda/io/github/innobridge/llama/Linux/x86_64

# Thread pool settings for maximum throughput
spring.task.execution.pool.core-size=4
spring.task.execution.pool.max-size=8
spring.task.execution.pool.queue-capacity=32

# Logging for performance monitoring
logging.level.io.github.innobridge=DEBUG
logging.level.root=INFO